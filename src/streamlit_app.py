import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import os
import pandas as pd
import matplotlib.pyplot as plt

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ASL ìˆ˜í™” ë¶„ë¥˜ê¸°", layout="wide")

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stButton>button {
        width: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

# ì œëª© ë° ì„¤ëª…
st.title("ASL(American Sign Language) ë¶„ë¥˜ê¸°")
st.markdown("í•™ìŠµëœ PyTorch ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜í™” ì•ŒíŒŒë²³ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

# 1. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (Notebookê³¼ ë™ì¼í•˜ê²Œ BatchNorm í¬í•¨)
class ASLClassifier(nn.Module):
    def __init__(self, input_size=784, num_classes=24):
        super(ASLClassifier, self).__init__()
        
        self.fc1 = nn.Linear(input_size, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.dropout1 = nn.Dropout(0.3)
        
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout2 = nn.Dropout(0.3)
        
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.dropout3 = nn.Dropout(0.2)
        
        self.fc4 = nn.Linear(128, num_classes)
        
        self.relu = nn.ReLU()

    def forward(self, x):
        # x shape: (batch, 784)
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout1(x)

        x = self.fc2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.dropout2(x)

        x = self.fc3(x)
        x = self.bn3(x)
        x = self.relu(x)
        x = self.dropout3(x)

        x = self.fc4(x)
        return x

# 2. ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_model():
    # notebookì—ì„œë„ device = 'cuda' if ... ì´ëŸ° ì‹ì´ë¼ ê·¸ëŒ€ë¡œ ë§ì¶¤
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = ASLClassifier().to(device)
    model_path = os.path.join(BASE_DIR, "model", "best_nnLinear_model.pth")
    
    if os.path.exists(model_path):
        try:
            # ğŸ”¥ map_state âŒ â†’ map_location âœ…
            state = torch.load(model_path, map_location=device)
            
            # í•™ìŠµ ë•Œì™€ êµ¬ì¡°ê°€ ë™ì¼í•˜ë¯€ë¡œ strict=Trueë¡œ ë¡œë”©í•´ë„ ë¨
            missing, unexpected = model.load_state_dict(state, strict=False)
            # ë””ë²„ê¹… ì›í•˜ë©´ ì•„ë˜ ë¡œê·¸ ì¼œë„ ë¨
            # print("missing keys:", missing)
            # print("unexpected keys:", unexpected)

            model.eval()
            return model, device
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, device
    else:
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None, device

model, device = load_model()

# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (Notebookì˜ test_transformê³¼ ë™ì¼í•˜ê²Œ ToTensorë§Œ ì‚¬ìš©)
def process_image(image):
    # Grayscale ë³€í™˜
    image = image.convert('L')
    # 28x28 ë¦¬ì‚¬ì´ì¦ˆ
    image = image.resize((28, 28))
    
    # Notebookì˜ test_transform = transforms.ToTensor()
    transform = transforms.Compose([
        transforms.ToTensor(),
        # Normalize ì•ˆ ì¼ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘ê¸°
    ])
    
    image_tensor = transform(image)  # (1, 28, 28)
    # Flatten (1, 784)
    image_tensor = image_tensor.view(1, -1)
    
    return image_tensor, image

# 4. ì˜ˆì¸¡ í•¨ìˆ˜
def predict(model, image_tensor, device):
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        outputs = model(image_tensor)
        probs = torch.softmax(outputs, dim=1)
        
        # ìƒìœ„ 3ê°œ ì˜ˆì¸¡
        top3_prob, top3_idx = torch.topk(probs, 3)
        
    return top3_prob.cpu().numpy()[0], top3_idx.cpu().numpy()[0]

# ë ˆì´ë¸” ë§¤í•‘ (J, Z ì œì™¸)
# Notebook ê¸°ì¤€: 0~23 â†’ A~Y (J, Z ì œì™¸) êµ¬ì¡°ì™€ ë™ì¼
label_to_letter = {i: chr(65+i) if i < 9 else chr(65+i+1) for i in range(24)}

# --- UI êµ¬ì„± ---

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("1. ì´ë¯¸ì§€ ì„ íƒ")
    option = st.radio("ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ:", ("ìƒ˜í”Œ ì´ë¯¸ì§€", "ì´ë¯¸ì§€ ì—…ë¡œë“œ"))
    
    input_image = None
    
    if option == "ìƒ˜í”Œ ì´ë¯¸ì§€":
        sample_dir = os.path.join(BASE_DIR, "data", "asl_image")
        if os.path.exists(sample_dir):
            sample_files = [f for f in os.listdir(sample_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            selected_sample = st.selectbox("ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", sample_files)
            
            if selected_sample:
                image_path = os.path.join(sample_dir, selected_sample)
                input_image = Image.open(image_path)
                st.image(input_image, caption=f"ì„ íƒëœ ìƒ˜í”Œ: {selected_sample}", width=300)
        else:
            st.warning("ìƒ˜í”Œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    else:  # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['png', 'jpg', 'jpeg'])
        if uploaded_file is not None:
            input_image = Image.open(uploaded_file)
            st.image(input_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=300)

with col2:
    st.subheader("2. ë¶„ì„ ê²°ê³¼")
    
    if input_image is not None and model is not None:
        if st.button("ë¶„ì„ ì‹œì‘", type="primary"):
            with st.spinner('ë¶„ì„ ì¤‘...'):
                # ì „ì²˜ë¦¬
                img_tensor, processed_img = process_image(input_image)
                
                # ì˜ˆì¸¡
                top3_prob, top3_idx = predict(model, img_tensor, device)
                
                # ê²°ê³¼ í‘œì‹œ
                top1_letter = label_to_letter.get(int(top3_idx[0]), '?')
                top1_conf = float(top3_prob[0] * 100)
                
                st.success(f"ì˜ˆì¸¡ ê²°ê³¼: **{top1_letter}**")
                st.metric(label="ì‹ ë¢°ë„ (Confidence)", value=f"{top1_conf:.2f}%")
                
                # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í™•ì¸ (ë””ë²„ê¹…ìš©)
                with st.expander("ì „ì²˜ë¦¬ëœ ì…ë ¥ ì´ë¯¸ì§€ ë³´ê¸° (28x28 Grayscale)"):
                    st.image(processed_img, width=100)
                
                # ìƒìœ„ 3ê°œ í™•ë¥  ì‹œê°í™”
                st.markdown("### ìƒìœ„ 3ê°œ ì˜ˆì¸¡ í™•ë¥ ")
                
                chart_data = pd.DataFrame({
                    'Alphabet': [label_to_letter.get(int(idx), '?') for idx in top3_idx],
                    'Probability': top3_prob * 100
                })
                
                # ë§‰ëŒ€ ê·¸ë˜í”„
                st.bar_chart(chart_data.set_index('Alphabet'))
                
                # ìƒì„¸ í‘œ
                st.table(chart_data.assign(Probability=lambda x: x['Probability'].map('{:.2f}%'.format)))
                
    elif model is None:
        st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì •ë³´
with st.sidebar:
    st.header("ëª¨ë¸ ì •ë³´")
    st.info("""
    - **ëª¨ë¸ êµ¬ì¡°**: MLP (Linear + BatchNorm + Dropout)
    - **ì…ë ¥**: 28x28 Grayscale Image (Flattened to 784)
    - **ì¶œë ¥**: 24 Classes (A-Y, excluding J, Z)
    - **í•™ìŠµ ë°ì´í„°**: Sign Language MNIST
    """)
    st.markdown("---")
    st.markdown("Created with Streamlit & PyTorch")
